%\subsection{State of the art}
%\label{sec:SoA}

One of the first early attempts to exploit active tactile exploration with passive stereo vision for object recognition was proposed by \citet{Allen1987Robotic}. In that paper, a rigid finger-like tactile sensor was used to trace along the surface with predefined movement cycles and provided a limited amount of information on object surface. The work was later extended to develop different exploratory procedures to acquire and interpret 3D touch information \citet{Allen1990Acquisition}. The exploratory procedures were, however, commanded by a human experimenter and therefore not linked to a fully autonomous system.

Single finger tactile exploration strategies for recognizing polyhedral objects have also been presented and evaluated in simulation, see for instance the work by \citet{Roberts1990ICRA} and \citet{Caselli1996ICRA}. In \citet{Moll2003STAR} a method for reconstructing shape and motion of an unknown convex object using three sensing fingers is presented. In that approach, friction properties must be known in advance and the surface is required to be smooth, i.e., it must have no corners or edges. Moreover, multiple simultaneous sensor contacts points are required resulting in additional geometric constraints for the setup.

%The early work by \citet{Allen1987Robotic} presents a hierarchical representation of the object. The tactile exploration strategy to refine is driven by local geometry features. This is engaged by using surface tracing algorithms. In that work, it is literally said: ``Given a starting and ending point on a surface, the sensor traces along the surface reporting its contact positions and normals as it moves along.'' However, no indication is given in how to determine those starting and ending points on the surface. \citet{Allen1990Acquisition} blah blah

In the work of \citet{Petrovskaya2011Global}, exploratory procedures have been considered with the aim to globally localize an object of known shape. Since the Bayesian posterior estimation for objects in 6D is known to be computationally expensive, that paper proposes an efficient approach, termed Scaling Series, that approximates the posterior by particles. For fully constraining datasets, that approach performs the estimation in under $1$ s with very high reliability.

In the paper presented by \citet{Meier2011Probabilistic} the tactile shape reconstruction employs a Kalman filter, while in \citet{Bierbaum2008Potential} the tactile exploration is guided by Dynamic Potential Fields for motion guidance
of the fingers. Here, the authors show that grasp affordances may be generated from geometric features extracted from the contact point set extracted during tactile exploration.

Interestingly, \citet{Sommer2014Bimanual} proposes a bimanual compliant tactile exploration that uses the GP representation to smooth noisy point data, but does not exploit the GP representation to define specific exploratory strategies.

\cite{Dragiev2011Gaussian} presents one of the first works that employs Gaussian Process Implicit Surfaces (GPIS) for the concurrent representation of the object shape and to guide grasping actions towards the object. However, that work concentrates only on the mean of the shape distribution, i.e. the maximum a posteriori (MAP) estimate of the shape and practically ignores one of the gains of the GP --- the error bars.
Later work by the same authors \citep{Dragiev2013Uncertainty} offers also a way to give preference to regions of the model with particular certainty level and introduce the notion of explore-grasp and exploit-grasp primitives.

\citet{Bjorkman2013Enhancing} focuses the attention on building object models that can be extracted with a small number of actions (multiple touches at once by tactile arrays) with the ultimate aim of understanding the category objects belong to, rather than exhaustively trying to explore the whole object. In that paper, the implicit function representation of the object surface is modelled by Gaussian Process regression as well, where the shape of the GP is governed by the thin plate covariance function derived by \citet{Williams2007Gaussian}. A set of predefined tactile glances are performed on the object: however, these are not updated as the object model gets refined as successive touches are performed. That paper, though, is the closest work to ours among the references. The main difference being: the space in which the next-best exploratory action is computed, the grain size to compute the predicted shape, and the ending condition for the overall algorithm.
%//, and the descriptor used.
\citet{Bjorkman2013Enhancing}
% use Zernike moments which imply extra computation time, and lack of a probabilistic interpretation, which is one of advantages of using Gaussian Process in first place. Moreover,
% CR: we don't use the model in the end for anything, so we can't compare to the descriptors they use for discrimination
proposes that the the exploratory actions are to be searched in a discrete space in the vertical direction and the approach angle, which seem extrinsic to the shape model. Using the ambient space instead of the intrinsic representation does not guarantee that the new observations will be on the desired shape region to be explored. Moreover, since they are interested in a model that is useful for categorization, they propose Zernike moments to make it affine invariant, for which a fine-grained explicit representation is required. We also propose to compute the predicted shape but with a very coarse grain for collision avoidance purposes, an issue that is not considered in that work. Finally, the number of actions, or touches in that case, are limited to a certain number, and then ordered according to the closest point on the implicit function with higher variance. In contrast, we set the highest expected variance in the shape prediction, so we explore until, probabilistically speaking, that goal is achieved.
%Comparing both that and this work is not easy due to the paradigmatical difference of the space in which the actions are searched. In their case, they benefit from several unprecise observations at once by tactile arrays, and in our case we focus on precise observations from an intrinsic tactile sensor. 